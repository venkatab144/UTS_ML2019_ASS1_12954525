{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_A1_12954525.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkatab144/UTS_ML2019_ASS1_12954525/blob/master/ML_A1_12954525.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYWl-5S3n3QD",
        "colab_type": "text"
      },
      "source": [
        "# Notes\n",
        "\n",
        "[1] Bottou, L. & LeCun, Y. 2005, 'Graph Transformer Networks for Image Recognition', <http://yann.lecun.com/exdb/publis/pdf/bottou-05.pdf>\n",
        "\n",
        "[2] https://engmrk.com/lenet-5-a-classic-cnn-architecture/\n",
        "\n",
        "[3] https://medium.com/@sh.tsang/paper-brief-review-of-lenet-1-lenet-4-lenet-5-boosted-lenet-4-image-classification-1f5f809dbf17\n",
        "\n",
        "[4] https://en.wikipedia.org/wiki/Convolutional_neural_network#Design\n",
        "\n",
        "[5] Towards Data Science 2019, viewed 26 August 2019, <https://towardsdatascience.com/illustrated-10-cnn-architectures-95d78ace614d#e276>\n",
        "\n",
        "[6] https://dataconomy.com/2017/04/history-neural-networks/\n",
        "\n",
        "[7] https://medium.com/@pechyonkin/key-deep-learning-architectures-lenet-5-6fc3c59e6f4\n",
        "\n",
        "[8] https://colab.research.google.com/drive/1CVm50PGE4vhtB5I_a_yc4h5F-itKOVL9#scrollTo=1w66ueiLlP0k&forceEdit=true&offline=true\n",
        "\n",
        "[9] Medium 2018, viewed August 26 2019, <https://medium.com/@vijendra1125/alexnet-overview-75880645b14c>\n",
        "\n",
        "[10] https://adeshpande3.github.io/adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html\n",
        "\n",
        "[11] https://en.wikipedia.org/wiki/AlexNet\n",
        "\n",
        "[12] https://en.wikipedia.org/wiki/Yann_LeCun\n",
        "\n",
        "[13] LeCun, Y., Bottou, L., Bengio, Y. & Haffner, P. 1998, 'Gradient-Based Learning Applied to Document\n",
        "Recognition', Proceedings of the IEEE, vol. 86, viewed 20 August 2019, <https://ieeexplore.ieee.org/document/726791>\n",
        "\n",
        "[14] The Verge 2019, viewed 26 August 2019, <https://www.theverge.com/2019/3/27/18280665/ai-godfathers-turing-award-2018-yoshua-bengio-geoffrey-hinton-yann-lecun>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60cuvgukRncT",
        "colab_type": "text"
      },
      "source": [
        "# Draft and Experiment Area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_L8AZXERncV",
        "colab_type": "text"
      },
      "source": [
        "# Review Report on \"[LEC98] Convolutional Neural Network\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUOw1N3gRncW",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xS-Cem9208yg",
        "colab_type": "text"
      },
      "source": [
        "Convolutional Neural Networks (CNN) are Deep Learning Algorithms that are used primarily for pattern recognition and visual imagery analysis. They are comprised of various layers such the: input and output layers and many different hidden layers. Hidden layers within a CNN often contain convolution layers, pooling layers, normalization layers and fully connected layers. Hidden layers are located in between the input and output layers and use artificial neurons to take input, and through some activation function, produce an output - this is the feature extraction phase of the CNN. These inputs and outputs (of the hidden layers) are not observed by the training set and are masked or \"hidden\" by the activation function, hence the name \"hidden\" layers. \n",
        "\n",
        "The activation function is most commonly a RELU (Rectified Linear Unit) layer, but, at the time of publishing, RELU was not used, the first notable use of RELU was in AlexNet (2012) [Towards Data Science 2019]. Instead, LeNet-5 - the CNN architecture presented in this paper, utilizes a sigmoid squashing function:\n",
        "\n",
        "$$ f(a) = A tanh(Sa) $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yctSlqZARncW",
        "colab_type": "text"
      },
      "source": [
        "## Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNX-0Rx8RncX",
        "colab_type": "text"
      },
      "source": [
        "The paper \"Gradient Based Learning Applied to Document\n",
        "Recognition\" addresses the problem with the current approach, at the time of publishing, of single digit Optical Character Recognition (OCR). The problem highlighted by the paper for the existing method is \"that the recognition accuracy is largely determined by the ability of the designer to come up with an appropriate set of features\" [LeCun et al. 1998].\n",
        "\n",
        "The main objective of the paper is to describe and build a CNN architecture for a better pattern recognition system, that employs a more automatic learning approach to pattern recognition. The existing methods used a combination of modules: a feature extraction module and a classifier module as seen in figure 1, in order to isolate characters and transform them into patterns so that they can be compared to a set of pre-determined characters and classified accordingly.\n",
        "\n",
        "![Traditional Pattern Recognition Architecture](https://github.com/venkatab144/UTS_ML2019_ASS1_12954525/blob/master/TraditionPatternRecognition.PNG?raw=true)\n",
        "\n",
        "*Figure 1: LeCun et al. 1998*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSa0kQ9AKeSy",
        "colab_type": "text"
      },
      "source": [
        "The paper uses the MNIST dataset which comprises of a series of handwritten digits, in order to show that the traditional model for recognition systems can be replaced by the Graph Transformer Network (GTN) design paradigm. The paper uses various different learning algorithms and compares their performance and accuracy using the MNIST dataset as a benchmark for hand written digit recognition. Gradient-Based Learning is the procedure that is used to modify the parameters of the function in order the minimise the error for the global loss function. In order to minimise the error for the global loss function, a back-propogation algorithm is used to compute the gradient of the loss function with respect to all parameters being used for the algorithm. Gradient-Based Learning is used to modify the parameters of the system using the calculated gradients, and using Gradient Back-Propogation, it is possible to identify the ideal parameters, weights and biases for the algorithm.\n",
        "\n",
        "The solution proposed by the paper is the LeNet-5 CNN Digit Recognition Architecture. The paper continues on to address the segmentation and recognition of multiple combined objects, in this context; multiple characters, by using a Graph Transformer Network and a Viterbi Transformer to analyse each character and produce a graph with a singular path which has the lowest Viterbi Penalty, this represents the best interpretation of the multiple characters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M3gu9NbRncY",
        "colab_type": "text"
      },
      "source": [
        "## Innovation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWXqj4p_RncY",
        "colab_type": "text"
      },
      "source": [
        "The paper proposed the idea of creating a CNN architecture that relied less on hand-crafted heuristics in order to isolate feature sets, and instead relied more on automatic learning and convolutions that allowed the architecture to use less memory (measured by number of variables) and perform less multiply-accumulate operations on the CPU, by storing learnable parameters.\n",
        "\n",
        "<img src=\"https://github.com/venkatab144/UTS_ML2019_ASS1_12954525/blob/master/memoryrequirements.png?raw=true\" width= 345px;/>\n",
        "<img src=\"https://github.com/venkatab144/UTS_ML2019_ASS1_12954525/blob/master/multipleaccumulate.png?raw=true\" width= 358px;/>\n",
        "\n",
        "*Figures 2 ,3: Memory Requirements and multiply-accumulate operations compared to other architectures [LeCun et al. 1998]*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LyUR-HeU-rn",
        "colab_type": "text"
      },
      "source": [
        "GPU's were not used at that time to help with training and instead the workload was place on CPU's which were considerably slower.\n",
        "\n",
        "LeNet-5 consists of 8 layers:\n",
        "1.   Input Layer: takes a 32x32 image.\n",
        "2.   Convolutional Layer C1: 6 feature maps at 28x28, 5x5 receptive fields are used with a Stride length of 1.\n",
        "3.   Subsampling (Pooling) Layer S2: Average pooling is applied and receptive fields with Stride length 2 are used to create 6 feature maps of size 14x14.\n",
        "4.   Convolutional Layer C3: Further convolusions are applied and 16 feature maps at 10x10 are created. 10 of the 16 feature maps generated in this layer are combined with the 6 feature maps generated in the S2 layer at identical locations [TABLE 1].\n",
        "5.   Subsampling (Pooling) Layer S4: Same as S2, produces 16 feature maps at 5x5.\n",
        "6.   Fully Connected Convolutional Layer C5: Has 120 feature maps of size 1x1.\n",
        "7.   Fully Connected Layer F6: 84 neurons. Every layer (excluding the input layer) up to F6 are passed through an activation function. But first the dot product of all the layers is computed for the input vector and its associated weight vector, and the appropriate bias, which was calculated using Gradient Back-Propagation, is added. The activation function for these layers is a sigmoid squashing function defined as: \n",
        "$$ f(a) = Atanh(Sa) $$ \n",
        "\n",
        "    The calculated dot product $ a_{i} $ is passed through this activation function for the given unit $ i $. $$ x_{i} = f(a_{i}) $$\n",
        "8.   Output Layer: The output layer is another fully connected layer with 10 possible values representing the digits from 0-9. The activation function for this layer is the Euclidean Radial Basis Function (RBF):\n",
        "\n",
        "$$ y_{i} = \\sum_{j}(x_{j} - w_{ij})^2 $$\n",
        "\n",
        "<center>Euclidean Radial Basis Function</center>\n",
        "\n",
        "\n",
        "![Figure 2: LeNet-5 Architecture. [LeCun et al. 1998]](https://github.com/venkatab144/UTS_ML2019_ASS1_12954525/blob/master/lenet5arch.PNG?raw=true)\n",
        "\n",
        "*Figure 4: LeNet-5 Architecture. [LeCun et al. 1998]*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dy-8Tp7nLo59",
        "colab_type": "text"
      },
      "source": [
        "The paper also discusses the problem of segmenting and recognising multiple objects stringed together such as: words, phone numbers, zip codes and check amounts (which was what LeNet-5 was commonly used for). It achieves this using Graph Transformer Networks and the Viterbi Transfomer which is based on the Viterbi Algorithm. The purpose of the Viterbi algorithm is to select the generated graphs with the lowest Viterbi Penalty, giving the best interpretation. \n",
        "\n",
        "The basic architecture provided in this paper which can be seen in figure 5, makes use of two graph transformers: recognition transformer and the viterbi transformer. The recognition transformer is responsible for analyzing the un-segmented object and using heuristic over-segmentation to generate all the possible segmentations for the given un-segmented input. The viterbi transformer takes all the possible interpretations of all the segmentations from the recognition transformer and computes the Viterbi path with the lowest Viterbi penalty. Each Viterbi path contains a start node, an arc and an end node. The arc holds the labels that represent a digit, analyzing the arcs from the graph obtained from the viterbi transformer will provide the results of the interpretation.\n",
        "\n",
        "![alt text](https://github.com/venkatab144/UTS_ML2019_ASS1_12954525/blob/master/viterbiarch.png?raw=true)\n",
        "\n",
        "*Figure 5: Simplified architecture using a Viterbi transformer for Multiple Object Recognition [LeCun et al. 1998]*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkKEAgiqYDHG",
        "colab_type": "text"
      },
      "source": [
        "The LeNet-5 architeture was significant at the time of publishing as it achieved an error rate of 0.70& which can be seen in figure 6. This architecture was one of the very first convolusional neural networks during its creation and its utilization of stacked convolution layers, pooling layers and the final fully connect layer containing the classifier, became a standard for future CNN architecture.\n",
        "\n",
        "![alt text](https://github.com/venkatab144/UTS_ML2019_ASS1_12954525/blob/master/errorrate.png?raw=true)\n",
        "\n",
        "*Figure 6: Error rate on MNIST test set, LeNet vs Other Architectures/Algorithms [LeCun et al. 1998]*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG2nh1hBRncZ",
        "colab_type": "text"
      },
      "source": [
        "## Technical quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s0lpF2BRnca",
        "colab_type": "text"
      },
      "source": [
        "The technical quality of the paper is very high, according to Google, it has been cited more than 20320 times, figure 7. \n",
        "\n",
        "![alt text](https://github.com/venkatab144/UTS_ML2019_ASS1_12954525/blob/master/articlecitations.PNG?raw=true)\n",
        "\n",
        "*Figure 7: Article citations*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kKLhe2zdcXp",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The techincal findings in this paper accompanied with in-depth explanation of all key components including the relevant math. The solution provided by the paper, and the information and innovation in the paper itself, laid the groundwork for future CNN architecutres such as AlexNet, which is regarded as one of the most influential papers published in the Computer Vision field [Medium 2018].\n",
        "\n",
        "The results and architectures proposed within the paper are easily replicable using Python and modern day machine learning libraries. The paper provides all the necessary detail and information required to be able to replicate the architecture and produce the same results yourself. The proposed solution in this paper was compared with other implementations of solutions that address the same issue of hand-written character recognition. \n",
        "\n",
        "The conclusions drawn from the paper are from the real world implementation of the LeNet-5 architecture, which, at the time, was being used by banks to identify the monetary amount on checks. The architecture was also tested against the MNIST dataset which contains more than 60,000 training patterns. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VXBXHXlRncb",
        "colab_type": "text"
      },
      "source": [
        "## Application and X-factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcNK1HNkRncb",
        "colab_type": "text"
      },
      "source": [
        "The proposed ideas in the paper were extremely promising at the time, especially in a field that was still in its early stages of inception. The notion of machine learning did not draw a lot of interest from the community during the publishing of the paper as stated by Yann LeCun himself: “There was a dark period between the mid-90s and early-to-mid-2000s when it was impossible to publish research on neural nets, because the community had lost interest in it,” says LeCun. “In fact, it had a bad rep. It was a bit taboo.” [The Verge 2019]. \n",
        "\n",
        "The LeNet architecture described in the paper is still widely used today and forms the basis of many CNN designs OCR systems around the world. The application domain of the paper is appropriate for the techniques described. It was one of the first CNN designs created and help pioneer its domain (Machine Learning/OCR).\n",
        "\n",
        "The concept of visual pattern recognition to classify handwritten characters can be further expanded upon, to the application domain of facial recognition or just general image recognition. The same design paradigms can be used to extract feature sets from images and perform classification tasks. In fact, Yan LeCun, the author, is the Chief AI Scientist at Facebook, which involves facial and image recognition. LeCun also notably recieved the Turing award for his contributions to the Deep Learning field in 2018.\n",
        "\n",
        "The work described in the paper can most definately spark discussion in class. The paper explains all the concepts in a way that anyone with basic knowledge in machine learning will be able to follow. The mathematical concepts and formulae present in the paper, however, are a bit harder to grasp. A fundamental knowledge of the ideas presented in the paper would be extremely beneficial if taught to individuals who are interested in the machine learning field but only possess a basic knowledge. It is a good starting step for anyone looking at the field to form a basic understanding of the designs and architecture behind CNN and other Deep Learning principles. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mywlhk3TRncc",
        "colab_type": "text"
      },
      "source": [
        "## Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwrUiPJjRnce",
        "colab_type": "text"
      },
      "source": [
        "The paper was structured excetionally well. It has a reading flow that will slowly introduce all concepts present and bring the reader up to the necessary knowledge required, before introducing any tougher/complicate topics. All content is sufficiently explained and at no point during the machine learning sections of the paper did I find myself stuck or needing assistance. Images are clearly displayed and labeled, graphs are also excellently presented.\n",
        "\n",
        "It is worth noting that even after almost 21 years, the diagrammatic representation of LeNet-5's architecture in this paper, is still widely used to present the basics of CNN and Deep Learning models, a testament to the timeless quality of the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wybpRC_DRncf",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "[SHA48][1]: Author, Title, Info\n",
        "\n",
        "[1]:https://google.com"
      ]
    }
  ]
}