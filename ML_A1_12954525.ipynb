{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_A1_12954525.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "60cuvgukRncT"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkatab144/UTS_ML2019_ASS1_12954525/blob/master/ML_A1_12954525.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYWl-5S3n3QD",
        "colab_type": "text"
      },
      "source": [
        "# Notes\n",
        "\n",
        "Paper reviews various different methods to handwritten OCR.\n",
        "\n",
        "better pattern recognition systems can be built by relying more on automatic learning and less on hand-designed heuristics\n",
        "\n",
        "This paper published in 1998, at that time\n",
        "SVM (and kernel learning) are quite popular.\n",
        "Hand-crafted features (e.g. SIFT) are dominant.\n",
        "MNIST (58k images) is a big and challenging data.\n",
        "Paper became popular only at 2012 after AlexNet CNN won at ImageNet challenge\n",
        "\n",
        "\n",
        "    traditional way of building recognition systems by\n",
        "manually integrating individually designed modules can be\n",
        "replaced by a uni\u0005ed and well\u0003principled design paradigm\u0004\n",
        "called Graph Transformer Networks\n",
        "\n",
        "variability and richness of natural data\u0004\n",
        "be it speech\u0004 glyphs\u0004 or other types of patterns\u0004 make it\n",
        "almost impossible to build an accurate recognition system\n",
        "entirely by hand\u0002\n",
        "\n",
        "most pattern recognition\n",
        "systems are built using a combination of automatic learn\u0003\n",
        "ing techniques and hand\u0003crafted algorithms\n",
        "\n",
        "The usual\n",
        "method of recognizing individual patterns consists in divid\u0003\n",
        "ing the system into two main modules shown\n",
        "\n",
        "feature extractor\u0004 transforms\n",
        "the input patterns so that they can be represented by low\u0003\n",
        "dimensional vectors or short strings of symbols\n",
        "\n",
        "The classi\u0005er\u0004 on the other hand\u0004 is often general\u0003purpose\n",
        "and trainabl\n",
        "\n",
        "One of the main problems with this ap\u0003\n",
        "proach is that the recognition accuracy is largely deter\u0003\n",
        "mined by the ability of the designer to come up with an\n",
        "appropriate set of features\u0002 This turns out to be a daunt\u0003\n",
        "ing task which\u0004 unfortunately\u0004 must be redone for each new\n",
        "problem\u0002 A\n",
        "\n",
        "A combination of three factors\n",
        "have changed this vision over the last decade\u0002 First\u0004 the\n",
        "availability of low\u0003cost machines with fast arithmetic units\n",
        "allows to rely more on brute\u0003force \fnumerical\n",
        " methods\n",
        "than on algorithmic re\u0005nements\n",
        "\n",
        "Second\u0004 the availability\n",
        "of large databases for problems with a large market and\n",
        "wide interest\u0004 such as handwriting recognition\u0004 has enabled\n",
        "designers to rely more on real data and less on hand\u0003crafted\n",
        "feature extraction to build recognition systems\u0002 The third\n",
        "and very important factor is the availability of powerful ma\u0003\n",
        "chine learning techniques that can handle high\u0003dimensional\n",
        "inputs and can generate intricate decision functions when\n",
        "fed with these large data sets\u0002\n",
        "\n",
        "recent progress in the accuracy of speech and handwriting\n",
        "recognition systems can be attributed in large part to an\n",
        "increased reliance on learning techniques and large training\n",
        "data sets\u0002\n",
        "\n",
        "large proportion of\n",
        "modern commercial OCR systems use some form of multi\u0003\n",
        "layer Neural Network trained with back\u0003propagation\n",
        "\n",
        "https://engmrk.com/lenet-5-a-classic-cnn-architecture/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60cuvgukRncT",
        "colab_type": "text"
      },
      "source": [
        "# Draft and Experiment Area"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpBLaxOGRncU",
        "colab_type": "text"
      },
      "source": [
        "1. First impression\n",
        "    * What is my chosen paper to read?\n",
        "        - Lec98 - Convolutional Nueral Networks\n",
        "    * What type of the main contribution the paper has made?\n",
        "        - A theory or proposition (revealing something, from unknown to known)\n",
        "        - A method or algorithm (inventing a technique, from undoable to doable)\n",
        "\n",
        "    * _Before_ reading the main body of the paper, write down your first impression  obtained from its abstract and short introduction.\n",
        "    * Why does the paper attract you, such as, How it surprised you? Why do you think it addresses an important topic that will be helpful in your future study of machine learning?\n",
        "    \n",
        "2. Read the paper abstract and introduction, list here all the notions that you don't know the precise meaning. If you think you have completed your list,  compare the list with people around you who have chosen the same or a similar paper.\n",
        "\n",
        "3. (During the next 7 days) Re-consider the central problem of the paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_L8AZXERncV",
        "colab_type": "text"
      },
      "source": [
        "# Review Report on \"[LEC98] Convolutional Neural Network\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUOw1N3gRncW",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Convolutional Neural Networks (CNN) are Deep Learning Algorithms that are used primarily for pattern recognition and visual imagery analysis. They are comprised of various layers such the: input and output layers and many different hidden layers. Hidden layers within a CNN often contain convolution layers, pooling layers, normalization layers and fully connected layers. Hidden layers are located in between the input and output layers and use artificial neurons to take input, and through some activation function, produce an output - this is the feature extraction phase of the CNN. These inputs and outputs (of the hidden layers) are not observed by the training set and are masked or \"hidden\" by the activation function, hence the name \"hidden\" layers. The activation function is most commonly a RELU (Rectified Linear Unit) layer, but, at the time this paper was published, RELU was not used, the first notable use of RELU was in AlexNet (2012)[S]. Instead, LeNet-5 - the CNN architecture presented in this paper, utilizes a sigmoid squashing function [PUT FUNCTION HERE]. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yctSlqZARncW",
        "colab_type": "text"
      },
      "source": [
        "## Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNX-0Rx8RncX",
        "colab_type": "text"
      },
      "source": [
        "The research is about .... A theorem has been proved stating ... / An algorithm of ... has been proposed.\n",
        "\n",
        "The paper \"Gradient Based Learning Applied to Document\n",
        "Recognition\" addresses the problem with the current approach, at the time of publishing, of single digit Optical Character Recognition (OCR). The problem highlighted by the paper for the existing method is \"that the recognition accuracy is largely determined by the ability of the designer to come up with an appropriate set of features\"[S]\n",
        "\n",
        "The main objective of the paper is to describe and build a CNN architecture for a better pattern recognition system, that employs a more automatic learning approach to pattern recognition. The existing methods used a combination of modules: a feature extraction module and a classifier module as seen in figure 1, in order to isolate characters and transform them into patterns so that they can be compared to a set of pre-determined characters and classified accordingly.\n",
        "\n",
        "The paper uses the MNIST dataset which comprises of a series of handwritten digits, in order to show that the traditional model for recognition systems can be replaced by the Graph Transformer Network (GTN) design paradigm. The paper uses various different learning algorithms and compares their performance and accuracy using the MNIST dataset as a benchmark for hand written digit recognition. Gradient-Based Learning is the procedure that is used to modify the parameters of the function in order the minimise the error for the global loss function. In order to minimise the error for the global loss function, a back-propogation algorithm is used to compute the gradient of the loss function with respect to all parameters being used for the algorithm. Gradient-Based Learning is used to modify the parameters of the system using the calculated gradients, and using Gradient Back-Propogation, it is possible to identify the ideal parameters, weights and biases for the algorithm.\n",
        "\n",
        "The solution proposed by the paper is the LeNet-5 CNN Digit Recognition Architecture. LeNet-5 consists of 8 layers:\n",
        "1.   Input Layer: takes a 32x32 image.\n",
        "2.   Convolutional Layer C1: 6 feature maps at 28x28, 5x5 receptive fields are used with a Stride length of 1.\n",
        "3.   Subsampling (Pooling) Layer S2: Average pooling is applied and receptive fields with Stride length 2 are used to create 6 feature maps of size 14x14.\n",
        "4.   Convolutional Layer C3: Further convolusions are applied and 16 feature maps at 10x10 are created. 10 of the 16 feature maps generated in this layer are combined with the 6 feature maps generated in the S2 layer at identical locations [TABLE 1].\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M3gu9NbRncY",
        "colab_type": "text"
      },
      "source": [
        "## Innovation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWXqj4p_RncY",
        "colab_type": "text"
      },
      "source": [
        "The background at the time of the work is that people understood the problem as .... The creative idea is ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG2nh1hBRncZ",
        "colab_type": "text"
      },
      "source": [
        "## Technical quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s0lpF2BRnca",
        "colab_type": "text"
      },
      "source": [
        "The technical development if of high/low quality. The authors supported their theory using ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VXBXHXlRncb",
        "colab_type": "text"
      },
      "source": [
        "## Application and X-factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcNK1HNkRncb",
        "colab_type": "text"
      },
      "source": [
        "I find the proposal in the paper promising. ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mywlhk3TRncc",
        "colab_type": "text"
      },
      "source": [
        "## Presentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwrUiPJjRnce",
        "colab_type": "text"
      },
      "source": [
        "The overall strucutre is clear. I found reading is easy / difficult. The paper could have been more attractive if the authors had organised ... / provided ... "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wybpRC_DRncf",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "[SHA48][1]: Author, Title, Info\n",
        "\n",
        "[1]:https://google.com"
      ]
    }
  ]
}